{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4trqL1pEaVD"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install -qU python-dotenv\n",
        "!pip install -qU langchain_core\n",
        "!pip install -qU langchain_mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBG05Zrt-oUn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MISTRAL_API_KEY\"]=\"YOUR API KEY HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-UvPnUMEzE6",
        "outputId": "1b38a095-d4fc-4efc-cce8-10771a234cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting interview_assistant.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile interview_assistant.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "load_dotenv()\n",
        "class InterviewAssistant:\n",
        "  def __init__(self):\n",
        "    self.llm = ChatMistralAI(\n",
        "        model=\"mistral-large-latest\",\n",
        "        api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
        "        temperature=0.1,\n",
        "        max_retries=2,\n",
        "    )\n",
        "\n",
        "\n",
        "  def interview_process_by_assitant(self,question,history):\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\n",
        "                \"system\",\n",
        "                \"\"\"Your are the hr assitant for talentScount you will be assit for inizial screening.Your task is gather information from candidate one by one and one of the information[First show the details that could be ask then ask one by one] is tech stack ask 3 or 4 technical questions to canditate based on tech stack and ask technical questions one by one analyze the converstation histroy for maintain correct flow woth candidate.Once the inizial screening process completely done ending greeting with we cantact throw your email for the canditate.After the process candidate give any ending grettings like Thankyou response to this\n",
        "\n",
        "                Information you need to gather:\n",
        "                  Full Name\n",
        "                  Email Address\n",
        "                  Phone Number\n",
        "                  Years of Experience\n",
        "                  Desired Position(s)\n",
        "                  Current Location\n",
        "                  Tech Stack\n",
        "\n",
        "\n",
        "                Return Format Should be like this:\n",
        "                      {{\n",
        "                        \"full_name\": \"string\",\n",
        "                        \"email\": \"string\",\n",
        "                        \"phone_number\": \"string\",\n",
        "                        \"years_of_experience\": \"string\",\n",
        "                        \"desired_position\": \"string\",\n",
        "                        \"current_location\": \"string\",\n",
        "                        \"tech_stack\": \"string\"\n",
        "                        \"technical_questions_and_answers\": [{{\"question1\":\"answer1\",\"question2\":\"answer2\",\"question3\":\"answer3\"}}]\n",
        "                      }}\n",
        "\n",
        "                Example for technical question based on tech stack:\n",
        "                  example tech stack: programming languages, frameworks, databases, and tools they are proficient in.\n",
        "                  you need ask technical questions from this skills one by one\n",
        "\n",
        "                Thinks to be reminder:\n",
        "                    analyse history for maintain correct flow with candidate\n",
        "                    first[staring] show what are the information you need ask then ask one by one information\n",
        "                    provide meaningful responses do not have string like this \"[Provide your answer or name...]\n",
        "                    once all the process completed give end greetings.\n",
        "                    We follow all GDPR guidelines to protect your privacy so candidate not intersted to share this information give end greetings.\n",
        "                \"\"\",\n",
        "            ),\n",
        "            (\"human\", \"{candidate_input}  {history}\",)\n",
        "        ])\n",
        "        chain = prompt | self.llm\n",
        "        llm_response=chain.invoke(\n",
        "                {\n",
        "                    \"candidate_input\": question,\n",
        "                    \"history\": history,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        result=llm_response.content\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXbv5R0l8w3D",
        "outputId": "d5092026-fe71-4da3-9d79-9a4caab19646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import re\n",
        "import streamlit as st\n",
        "from interview_assistant import InterviewAssistant\n",
        "\n",
        "interview_assistant=InterviewAssistant()\n",
        "\n",
        "\n",
        "st.header(\"TalentScout Interview Assistant\")\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "if \"inisial_message\" not in st.session_state:\n",
        "    st.session_state.inisial_message = []\n",
        "\n",
        "with st.chat_message(\"assistant\"):\n",
        "    msg_to_candidate=\"To assist you better, we kindly request your name, email, and phone number. Your information will be handled securely and will not be shared with anyone. We follow all GDPR guidelines to protect your privacy. Do you agree to share this information?\"\n",
        "    st.markdown(msg_to_candidate)\n",
        "    st.session_state.inisial_message.append({\"role\": \"assistant\", \"content\": msg_to_candidate})\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "\n",
        "if prompt := st.chat_input(\"What is up?\"):\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    response=interview_assistant.interview_process_by_assitant(prompt,[st.session_state.inisial_message,st.session_state.messages])\n",
        "\n",
        "    pattern = r'(\\{\\s*\"full_name\":.*\\})'\n",
        "\n",
        "    match = re.search(pattern, response, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        extracted_json = match.group(1)\n",
        "        print(extracted_json)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(response)\n",
        "    # Add assistant response to chat history\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0rot2GvthO4"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501 --subdomain interview-assistant"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
